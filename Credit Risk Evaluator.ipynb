{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(Path('Resources/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/2020Q1loans.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Predictions\n",
    "There are several considerations regarding the data.  It is an inbalanced data set with over 10 features, which theoretically would be handled best by Random Forest Classifier.  However, a quick, informed decision is usually desirable in a financial setting, which is a strong point of Logistic Regression.\n",
    "\n",
    "---\n",
    "\n",
    "Based on these, I predict that random forest will provide the best results because of the size of the data set and number of features, which would be too noisy for logitic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for training data\n",
    "X_train = train_df.drop('loan_status', axis=1)\n",
    "\n",
    "X_train_dummies = pd.get_dummies(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for testing data\n",
    "X_test = test_df.drop('loan_status', axis=1)\n",
    "\n",
    "X_test_dummies = pd.get_dummies(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label_train = LabelEncoder().fit_transform(train_df['loan_status'])\n",
    "\n",
    "y_label_test = LabelEncoder().fit_transform(test_df['loan_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing dummy variables to testing set\n",
    "for col in X_train_dummies.columns:\n",
    "    if col not in X_test_dummies.columns:\n",
    "        X_test_dummies[col]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR (unscaled) Training Data Score: 0.6286535303776684\n",
      "LR (unscaled) Testing Data Score: 0.5325393449595917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "clf_logistic  = LogisticRegression(solver='sag', max_iter=1000).fit(X_train_dummies, y_label_train) \n",
    "\n",
    "print(f\"LR (unscaled) Training Data Score: {clf_logistic.score(X_train_dummies, y_label_train)}\")\n",
    "print(f\"LR (unscaled) Testing Data Score: {clf_logistic.score(X_test_dummies, y_label_test)}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'log2', 'n_estimators': 700}\n"
     ]
    }
   ],
   "source": [
    "# Get best parameters for Forest Classifier\n",
    "rfc = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, oob_score = True) \n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 700],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train_dummies, y_label_train)\n",
    "print (CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF (unscaled) Training Score: 1.0\n",
      "RF (unscaled) Testing Score: 0.6095278604849\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "clf_forest = RandomForestClassifier(random_state=100, n_estimators=700, max_features= 'log2' ).fit(X_train_dummies, y_label_train)\n",
    "\n",
    "print(f'RF (unscaled) Training Score: {clf_forest.score(X_train_dummies, y_label_train)}')\n",
    "print(f'RF (unscaled) Testing Score: {clf_forest.score(X_test_dummies, y_label_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Prediction Analysis and Scaled Predictions\n",
    "As suspected, RF outperformed LR, but only minimally.  The largest difference is between the training scores.\n",
    "\n",
    "---\n",
    "\n",
    "Scaling the data should have some impact on LR's modeling capabilities, because of the number of features.  This will bring features tha different into the same ballpark, so to speak.  \n",
    "\n",
    "I still predict that RF will outperform LR because RF handles noisy data well already, and reducing that noise will only boost its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler().fit(X_train_dummies)\n",
    "X_train_scaled = scaler.transform(X_train_dummies)\n",
    "X_test_scaled = scaler.transform(X_test_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7128899835796387\n",
      "Testing Score: 0.7201190982560612\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "clf_lr_scaled = LogisticRegression(max_iter=300).fit(X_train_scaled, y_label_train)\n",
    "\n",
    "\n",
    "print(f'Training Score: {clf_lr_scaled.score(X_train_scaled, y_label_train)}')\n",
    "print(f'Testing Score: {clf_lr_scaled.score(X_test_scaled, y_label_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'log2', 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Get best parameters for Forest Classifier\n",
    "rfc2 = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, oob_score = True) \n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 700],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc2, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train_scaled, y_label_train)\n",
    "print (CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Testing Score: 0.6052743513398554\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "clf_rf_scaled = RandomForestClassifier(random_state=100, n_estimators=200, max_features=\"log2\").fit(X_train_scaled, y_label_train)\n",
    "\n",
    "print(f'Training Score: {clf_rf_scaled.score(X_train_scaled, y_label_train)}')\n",
    "print(f'Testing Score: {clf_rf_scaled.score(X_test_scaled, y_label_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Thoughts\n",
    "Surprisingly LR had the best final model, after the data was scaled.  RF remained mostly unchanged by the data being scaled, which matches initial prediction that it handles noise well.  Where it performed differently, was less noise did not translate to a better score.\n",
    "\n",
    "---\n",
    "\n",
    "In this scenario, I would use LR with a scaled data set as it provided the highest accuracy with a test score of .72, meaning that nearly 3 out of 4 loan requests are correctly classified with the right risk score, an acceptable measure that rules out human emotion in deciding whether or not to give a loan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
